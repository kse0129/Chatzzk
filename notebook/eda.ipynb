{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de5ab0c5-a112-4cec-af16-10d9ce54f0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9bfd92a-74c4-496c-be31-13202ab8449d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_dir = \"ChzzkChat/chat/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1743b800-ece1-4b56-94b1-385596c255b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_logs = [os.path.join(chat_dir, chat_log) for chat_log in os.listdir(chat_dir)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e627ef7e-8d28-43a8-8357-c3e14a4661c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_lines = []\n",
    "def bad_line_handler(line):\n",
    "    bad_lines.append(line)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd8bf3eb-9449-457f-924c-036f8ea1d551",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [\n",
    "    pd.read_csv(chat_log, sep=\"\\t\", encoding=\"utf-8\", header=None, on_bad_lines=bad_line_handler, engine='python')\n",
    "    for chat_log in chat_logs if os.path.getsize(chat_log) != 0\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2595fef4-eeef-4ca2-a1b7-b9982e079ea8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['탬탬버린', '2025-08-09 20:20:21', '채팅', '레인메iker', '대문자 ', '', 'E'],\n",
       " ['괴물쥐',\n",
       "  '2025-08-07 00:42:52',\n",
       "  '채팅',\n",
       "  '하루살이 오빠 2705',\n",
       "  '이 실력으로 어딜 간다고 ',\n",
       "  '브론즈?'],\n",
       " ['파카', '2025-08-05 02:14:38', '채팅', '오이김치찜', '구으다가 라이즣', 'ㅏㄴ테 맞은건가'],\n",
       " ['풍월량', '2025-08-08 21:42:31', '채팅', '풍바사삭', '저장은 되어잇는거같은데 못불러오는 버그잇나', '보네'],\n",
       " ['울프', '2025-08-06 16:39:55', '채팅', '결대로', '울프님 ', '보시기엔 어때요?']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f42474b-fad7-40fb-a284-49a76bb11ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_df = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2af52e4a-213b-4ce4-ba86-aeb5323c4822",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_df.columns = [\"streamer\", \"time\", \"type\", \"nickname\", \"chat\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "542bb4df-c158-4170-a3ee-ba4ba664918a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, nan, nan, ..., '어디갓지...', '침착맨은 방송하라 방송하라 방송하라',\n",
       "       '병거나 밥먹고 쉬자... 난 브레이크가 없어'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_df[\"chat\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65697182-6bea-48b8-973a-778aeeac8d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_df.dropna(ignore_index=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17517afa-dba7-458a-859d-499495325d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['이건', '대박', '헐']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def simple_tokenizer(text):\n",
    "    # 1. 소문자 변환 (원하면)\n",
    "    text = text.lower()\n",
    "    \n",
    "    # 2. 이모티콘 / 반복 문자 패턴 처리\n",
    "    text = re.sub(r\"ㅋ{2,}\", \" <laugh> \", text)\n",
    "    text = re.sub(r\"[ㅠㅜ]{2,}\", \" <cry> \", text)\n",
    "    \n",
    "    # 3. 특수문자 → 공백\n",
    "    text = re.sub(r\"[^가-힣\\s]\", \" \", text)\n",
    "    \n",
    "    # 4. 공백 기준 토큰 분리\n",
    "    tokens = text.split()\n",
    "    return tokens\n",
    "\n",
    "# ✅ 테스트\n",
    "print(simple_tokenizer(\"ㅋㅋㅋㅋ 이건 ㄹㅇ 대박 ㅠㅠ!! 헐ㅋㅋ\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15baa54-0dcb-4112-be9c-b2b0201025a0",
   "metadata": {},
   "source": [
    "#### 채팅, 후원 비율"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12d089eb-759e-4413-8427-ca3fdaa84734",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type\n",
       "채팅    99.503998\n",
       "후원     0.496002\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_df[\"type\"].value_counts(normalize=True) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34606094-5cf2-41c4-9453-98dace7aba42",
   "metadata": {},
   "source": [
    "#### 스트리머별 채팅 비율"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e42c9b9-2c4a-499c-a849-234af041c233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "streamer\n",
       "한동숙           10.439841\n",
       "풍월량           10.202747\n",
       "텐코 시부키         9.785309\n",
       "울프             7.176495\n",
       "시라유키 히나        6.620978\n",
       "아야츠노 유니        6.423637\n",
       "아라하시 타비        6.233266\n",
       "괴물쥐            5.804524\n",
       "하나코 나나         5.771093\n",
       "탬탬버린           5.745428\n",
       "아카네 리제         4.488384\n",
       "강지             3.710071\n",
       "파카             3.403749\n",
       "침착맨            3.401634\n",
       "네네코 마시로        2.868664\n",
       "아오쿠모 린         2.836007\n",
       "서새봄냥 SEBOM     2.814069\n",
       "다주             2.274106\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_df[\"streamer\"].value_counts(normalize=True) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "75050f50-a97b-4ad3-992a-84872f2f9853",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>streamer</th>\n",
       "      <th>time</th>\n",
       "      <th>type</th>\n",
       "      <th>nickname</th>\n",
       "      <th>chat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>다주</td>\n",
       "      <td>2025-08-06 15:01:06</td>\n",
       "      <td>채팅</td>\n",
       "      <td>하이안D</td>\n",
       "      <td>다하다하</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>다주</td>\n",
       "      <td>2025-08-06 15:01:08</td>\n",
       "      <td>채팅</td>\n",
       "      <td>주다영진심녀</td>\n",
       "      <td>다하다하</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>다주</td>\n",
       "      <td>2025-08-06 15:01:16</td>\n",
       "      <td>채팅</td>\n",
       "      <td>주다영진심녀</td>\n",
       "      <td>반갑다주</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>다주</td>\n",
       "      <td>2025-08-06 15:01:57</td>\n",
       "      <td>채팅</td>\n",
       "      <td>요리하는개백수탈출함</td>\n",
       "      <td>젠지 pc방</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>다주</td>\n",
       "      <td>2025-08-06 15:02:11</td>\n",
       "      <td>채팅</td>\n",
       "      <td>하이안D</td>\n",
       "      <td>젠지 PC방 진짜 궁금해요 ~</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  streamer                 time type    nickname              chat\n",
       "0       다주  2025-08-06 15:01:06   채팅        하이안D              다하다하\n",
       "1       다주  2025-08-06 15:01:08   채팅      주다영진심녀              다하다하\n",
       "2       다주  2025-08-06 15:01:16   채팅      주다영진심녀              반갑다주\n",
       "3       다주  2025-08-06 15:01:57   채팅  요리하는개백수탈출함            젠지 pc방\n",
       "4       다주  2025-08-06 15:02:11   채팅        하이안D  젠지 PC방 진짜 궁금해요 ~"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d9a3bad-75c4-4227-91bd-5104e3e29b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_df[\"token\"] = chat_df[\"chat\"].apply(simple_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca5bc56c-cf2b-4f18-aec7-1b535d360780",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chat_df.groupby('streamer')['token'].agg(lambda x: [item for sublist in x for item in sublist]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "85a7162e-b785-45f7-95fe-060678778851",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ChzzkChat/stopwords-ko.txt', 'r', encoding='utf-8') as f:\n",
    "    stopwords = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d08c8296-2fb3-4ddd-b1b1-f640d005a697",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['다주', '서새봄냥 SEBOM', '탬탬버린', '아라하시 타비', '괴물쥐', '텐코 시부키', '강지',\n",
       "       '한동숙', '시라유키 히나', '파카', '풍월량', '울프', '아오쿠모 린', '네네코 마시로', '아카네 리제',\n",
       "       '아야츠노 유니', '하나코 나나', '침착맨'], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_df[\"streamer\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e9c7d9be-2665-41ce-9cbd-db46e0f72968",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7da3dbc5-87dc-404b-8f81-ccf603009cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = result['token'].apply(lambda x : ' '.join(x)).values\n",
    "streamers = result[\"streamer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f2a83633-5cf7-4d89-b027-616ab6c2a67d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kse/anaconda3/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['sebom', '가서', '같은', '것과', '결과에', '결론을', '관계가', '관련이', '그런', '그럼에도', '그렇게', '그에', '그치지', '김에', '까닭에', '나나', '낫다', '네네코', '년도', '논하지', '누가', '다시', '달려', '대로', '대해', '되는', '되다', '되어', '들면', '들자면', '듯하다', '따르는', '따름이다', '따지지', '때가', '리제', '마시로', '만은', '만이', '많은', '말하면', '말할것도', '몰라도', '몰랏다', '못하다', '미치다', '바꾸어서', '바꿔', '밖에', '방면으로', '보면', '보아', '부류의', '비길수', '비추어', '뿐만', '사람들', '상대적으로', '생각이다', '서새봄냥', '서술한바와같이', '시라유키', '시부키', '쓰여', '아니다', '아니라', '아라하시', '아야츠노', '아오쿠모', '아카네', '안다', '안된다', '않고', '않기', '않는다면', '않다', '않다면', '않도록', '않으면', '알겠는가', '어쩔수', '없고', '없다', '예를', '외에', '요만한', '우에', '위에서', '유니', '이렇게', '이로', '이르다', '이와', '이유는', '인하여', '임에', '점에서', '정도에', '정도의', '종합한것과같이', '주저하지', '줄은', '지경이다', '타비', '텐코', '틀림없다', '편이', '하고', '하기', '하기만', '하나코', '하는', '하는것만', '하는것이', '하다', '하면', '하지', '한하다', '할수록', '함으로써', '해도', '해서는', '형식으로', '히나', '힘이'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "강지의 상위 10개 단어: 강하, 어어, 강지님, 이게, 강순이, 그건, 어라, 이거, 이제, 이야\n",
      "괴물쥐의 상위 10개 단어: 물쥐야, 물쥐님, 카타, 갱플, 대물쥐, 카르마, 물쥐, 카선족, 아칼리, 지금\n",
      "네네코 마시로의 상위 10개 단어: 안냐냐, 시로, 바냐냐, 오오, 너무, 오옹, 찌로, 시로가, 뭐야, 마시로\n",
      "다주의 상위 10개 단어: 다하, 다바다바, 다주님, 옥슈슈, 너무, 네즈코, 아님, 기흥, 다하다하, 왓더버거\n",
      "서새봄냥 SEBOM의 상위 10개 단어: 복돌이, 너무, 어우, 이거, 이게, 스승님, 새봄님, 마피아, 복도링, 역시\n",
      "시라유키 히나의 상위 10개 단어: 히나, 빠히나, 히나야, 디아루가, 어어, 오오, 너무, 히나가, 그건, 네넹\n",
      "아라하시 타비의 상위 10개 단어: 타비, 아라하시, 타비야, 어어, 어우, 약머거약, 채팅, 그건, 이게, 꼴림\n",
      "아야츠노 유니의 상위 10개 단어: 유니, 아야츠노, 야꾸머거, 채팅, 유니야, 유니가, 유니우승, 일루와잇, 노력합시다, 안녕하시지\n",
      "아오쿠모 린의 상위 10개 단어: 어어, 어우, 오우, 빠이린, 오오, 모린, 그건, 쿠모린, 우어터, 린이\n",
      "아카네 리제의 상위 10개 단어: 리제, 콘츕츕, 네네, 리제야, 엥나, 리제는, 레샤, 리제가, 너무, 그러게\n",
      "울프의 상위 10개 단어: 유나라, 너무, 빅버지, 든프, 이게, 라이즈, 빅토르, 이거, 어우, 이건\n",
      "침착맨의 상위 10개 단어: 궤도, 단군, 이광수, 없으면, 침착맨, 광수, 비행기, 광수형, 너무, 상하이\n",
      "탬탬버린의 상위 10개 단어: 그건, 채팅, 유나라, 너무, 이게, 탬바, 이거, 이건, 탬탬보리인, 이제\n",
      "텐코 시부키의 상위 10개 단어: 부키야, 부키, 어어, 너무, 오오, 누넴, 마자, 그러게, 부키가, 어우\n",
      "파카의 상위 10개 단어: 파카님, 갱플, 카타, 아칼리, 다팔고, 크산테, 유미, 구인수, 어어, 탄성팔\n",
      "풍월량의 상위 10개 단어: 너무, 이거, 풍형, 풍바, 이게, 어어, 풍하, 마피아, 이제, 뭐야\n",
      "하나코 나나의 상위 10개 단어: 반갑나나, 나나야, 나나, 오오, 페토, 너무, 나나가, 빠이나나, 생일, 빠나나\n",
      "한동숙의 상위 10개 단어: 갱플, 카르마, 카타, 우승, 그웬, 너무, 갬빗, 자르반, 이거, 크루\n"
     ]
    }
   ],
   "source": [
    "# TfidfVectorizer 사용하여 TF-IDF 계산, 불용어 제외\n",
    "vectorizer = TfidfVectorizer(stop_words=stopwords)\n",
    "\n",
    "# TF-IDF 행렬을 계산합니다\n",
    "X = vectorizer.fit_transform(documents)\n",
    "\n",
    "# TF-IDF 결과를 데이터프레임으로 변환\n",
    "df_tfidf = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out(), index=streamers)\n",
    "\n",
    "# 각 스트리머별로 상위 10개 단어 추출\n",
    "top_10_words = {}\n",
    "\n",
    "for streamer in df_tfidf.index:\n",
    "    # 각 스트리머의 TF-IDF 값을 기준으로 상위 10개 단어 추출\n",
    "    top_10 = df_tfidf.loc[streamer].sort_values(ascending=False).head(10)\n",
    "    top_10_words[streamer] = top_10.index.tolist()\n",
    "\n",
    "# 결과 출력\n",
    "for streamer, words in top_10_words.items():\n",
    "    print(f\"{streamer}의 상위 10개 단어: {', '.join(words)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
